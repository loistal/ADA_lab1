{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IS-Academia Analysis\n",
    "This is a data analysis of the IS-Academia data accessible by anyone, without authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal** : \n",
    "* Find out how much time do EPFL's students in Computer Science need to get their Bachelor. \n",
    "* Do a similar analysis for the Master's degree. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge before analysing the data is to extract this data from the IS-Academia website. By looking at this [page](http://isa.epfl.ch/imoniteur_ISAP/%21gedpublicreports.htm?ww_i_reportmodel=133685247), we can extract information about the names and different values of the HTML `<input>` fields using *Beautiful Soup*. Then we will be able to generate a valid request to get the wanted data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the requests using Postman\n",
    "\n",
    "With the *Postman interceptor*, we can intercept requests when submitting the form we are interested in. \n",
    "A valid request URL looks like this : \n",
    "\n",
    "`http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter?ww_b_list=1&ww_i_reportmodel=133685247&ww_c_langue=&ww_i_reportModelXsl=133685270&zz_x_UNITE_ACAD=Informatique&ww_x_UNITE_ACAD=249847&zz_x_PERIODE_ACAD=2016-2017&ww_x_PERIODE_ACAD=355925344&zz_x_PERIODE_PEDAGO=Bachelor+semestre+1&ww_x_PERIODE_PEDAGO=249108&zz_x_HIVERETE=Semestre+d%27automne&ww_x_HIVERETE=2936286&dummy=ok`\n",
    "\n",
    "You can see there are redundant information, for example : `zz_x_UNITE_ACAD=Informatique` and `ww_x_UNITE_ACAD=249847`. You can imagine that getting rid of one of them can still work. It's actually the case, you can get rid of all the `zz_x_*` parameters. With a closer analysis, you can see that the `ww_x_*` parameters correspond to the actual values in the HTML dropdowns.\n",
    "\n",
    "So this is also a valid request :\n",
    "\n",
    "`http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter?ww_b_list=1&ww_i_reportmodel=133685247&ww_c_langue=&ww_i_reportModelXsl=133685270&ww_x_UNITE_ACAD=249847&ww_x_PERIODE_ACAD=355925344&ww_x_PERIODE_PEDAGO=249108&ww_x_HIVERETE=2936286&dummy=ok`, much more simpler and shorter. \n",
    "\n",
    "Then the URL of the empty form page is given by \n",
    "`http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter?ww_i_reportmodel=133685247`\n",
    "which is a little bit different from the IS-Academia link above, because the page is using frames and their HTML code are not included in the base page. \n",
    "\n",
    "From here, you can already guess the form paramters we are going to use, but the goal is to extract them and not hardcode them. At least now we have the request base and format.\n",
    "\n",
    "IS-Academia generates a link, on which you can click to get the actual data. By inspecting the requests, we can see that the URL required to get the data contains all the parameters, and additionaly a parameter contained in the HTML source of the link, we will need to extract it to get the final data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the parameters using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principle used to extract the parameters here is basically to use the text description provided in the HTML page, and then play with the DOM to extract the wanted values. Parameters are returned as a dictionnary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Requests and Beautiful Soup\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the IS-Academia page\n",
    "empty_form_url = 'http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter?ww_i_reportmodel=133685247'\n",
    "\n",
    "# Get the page by doing a HTTP request\n",
    "empty_form = rq.get(empty_form_url)\n",
    "if empty_form.status_code != rq.codes.ok:\n",
    "    print(\"--> Error, I'm gonna crash... <--\")\n",
    "\n",
    "# Get the soup out of it\n",
    "form_soup = BeautifulSoup(empty_form.text, 'html.parser')\n",
    "\n",
    "def get_parameters(format, filters):\n",
    "    \"\"\"\n",
    "    Returns a dictionnary containing the paramters\n",
    "    \n",
    "    format : 'xls' or 'html', selects the data format\n",
    "    filters : dictionnary containing the values you want to select in the dropdowns\n",
    "    \"\"\"\n",
    "    # Parameters dictionnary\n",
    "    parameters = {}\n",
    "    \n",
    "    # First, get the checkbox parameters\n",
    "    checkbox = form_soup.find(text = format).parent\n",
    "    parameters[checkbox['name']] = checkbox['value']\n",
    "    \n",
    "    # Then get the dropdown parameters\n",
    "    for f in filters:\n",
    "        html_option = form_soup.find(text = f).parent\n",
    "        param_name = html_option.parent['name']\n",
    "        param_value = html_option['value']\n",
    "        parameters[param_name] = param_value\n",
    "        \n",
    "    # Don't forget the hidden fields\n",
    "    hidden = form_soup.find_all('input', type='hidden')\n",
    "    \n",
    "    # Ignore the zz_* fields, they are useless for what we want to do, \n",
    "    # also ignore ww_i_reportmodel, already contained in the base URL\n",
    "    for field in hidden:\n",
    "        if not (field['name'].startswith('z') or field['name'] == 'ww_i_reportmodel'):\n",
    "            parameters[field['name']] = field['value']\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parameters, we are able to get the desired link to the data, a little bit of work on this page and we can \"simulate\" a click on this link by generating the good request. The data is then saved in a file, and the `get_data` function returns its path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(parameters, format, filename):\n",
    "    \"\"\"\n",
    "    Returns a file path with the data\n",
    "    \n",
    "    url : url of the file to download\n",
    "    parameters : parameters of the request\n",
    "    format : 'html' or 'xls\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the webpage with the data link\n",
    "    link_page = rq.get(empty_form_url, parameters)\n",
    "    if link_page.status_code != rq.codes.ok:\n",
    "        print(\"--> Error, I'm gonna crash... <--\")\n",
    "    \n",
    "    # Get the soup out of it\n",
    "    link_soup = BeautifulSoup(link_page.text, 'html.parser')\n",
    "\n",
    "    # The interesting link is the second of the page, and the parameters in this context : onlick:\"...'name=value'\".\n",
    "    link_param = link_soup.find_all('a')[1]['onclick'].split('\\'')[1].split('=')\n",
    "    parameters[link_param[0]] = link_param[1]\n",
    "\n",
    "    # The request needs a capitalized xls\n",
    "    format = 'XLS' if format == 'xls' else format\n",
    "    \n",
    "    url = empty_form_url.replace('filter', format)\n",
    "        \n",
    "    # Thanks to http://stackoverflow.com/questions/16694907/how-to-download-large-file-in-python-with-requests-py\n",
    "    r = rq.get(url, parameters)\n",
    "    filename = filename + '.%s' % format\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # Filter out keep-alive new chunks\n",
    "                f.write(chunk) \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to fetch the desired data and save it in a file : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.html'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format = 'html'\n",
    "filters = ['Informatique', 'Bachelor semestre 1', '2016-2017', 'Semestre d\\'automne']\n",
    "filename = 'test'\n",
    "\n",
    "# Get the request parameters\n",
    "params = get_parameters(format, filters)\n",
    "\n",
    "# Save the actual data in a file\n",
    "get_data(params, format, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Data\n",
    "Now that we have the code to fetch the data, we can start to analyze it. But first, we need to get all the tables we are interested in. \n",
    "I consider that the values appearing in the dropdown buttons are given, they are available to any user browsing the website. So we will use it to retrieve the data we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Pandas and NumPy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The section is always Informatique. \n",
    "section = 'Informatique'\n",
    "\n",
    "# The academic period goes from 2007 to 2017\n",
    "acad_period = ['2007-2008', '2008-2009', '2009-2010', '2010-2011', '2011-2012', '2012-2013', '2013-2014', \n",
    "          '2014-2015', '2015-2016', '2016-2017']\n",
    "\n",
    "# The pedagogical period goes from Bachelor 1 to Bachelor 6\n",
    "peda_period = [['Bachelor semestre 1', 'Bachelor semestre 3', 'Bachelor semestre 5'], \n",
    "               ['Bachelor semestre 2', 'Bachelor semestre 4', 'Bachelor semestre 6']]\n",
    "\n",
    "# The semester type is either Semestre d'automne or Semestre de printemps\n",
    "semester_type = ['Semestre d\\'automne', 'Semestre de printemps']\n",
    "\n",
    "# Choose the html format\n",
    "format = 'html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch all the needed data and build dataframes out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a list of data frames\n",
    "dfs = []\n",
    "\n",
    "# Get all the possible files\n",
    "for year in acad_period: \n",
    "    for season in semester_type:\n",
    "        # Take only odd or even semesters, depending on the season\n",
    "        semesters = peda_period[0] if season == semester_type[0] else peda_period[1]\n",
    "        for sem in semesters: \n",
    "            filters = [section, year, season, sem]\n",
    "            filename = 'data/' + '_'.join(filters)\n",
    "            \n",
    "            # Get the request parameters\n",
    "            params = get_parameters(format, [section, year, season, sem])\n",
    "            \n",
    "            # Save the data\n",
    "            get_data(params, format, filename)\n",
    "            \n",
    "            # Read the file\n",
    "            df = pd.read_html(filename + '.' + format, skiprows=[0], header=0)[0]\n",
    "            \n",
    "            # Drop the NaN values, add the semester column\n",
    "            df['Semester'] = sem\n",
    "            df = df.dropna(axis=1)\n",
    "            \n",
    "            # Add to the list\n",
    "            dfs.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each request is in a dataframe, they are all contained in a list, it's time to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Civilité</th>\n",
       "      <th>Nom Prénom</th>\n",
       "      <th>Statut</th>\n",
       "      <th>No Sciper</th>\n",
       "      <th>Semester</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monsieur</td>\n",
       "      <td>Arévalo Christian</td>\n",
       "      <td>Présent</td>\n",
       "      <td>169569</td>\n",
       "      <td>Bachelor semestre 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monsieur</td>\n",
       "      <td>Aubelle Flavien</td>\n",
       "      <td>Présent</td>\n",
       "      <td>174905</td>\n",
       "      <td>Bachelor semestre 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monsieur</td>\n",
       "      <td>Badoud Morgan</td>\n",
       "      <td>Présent</td>\n",
       "      <td>173922</td>\n",
       "      <td>Bachelor semestre 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monsieur</td>\n",
       "      <td>Baeriswyl Jonathan</td>\n",
       "      <td>Présent</td>\n",
       "      <td>179406</td>\n",
       "      <td>Bachelor semestre 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monsieur</td>\n",
       "      <td>Barroco Michael</td>\n",
       "      <td>Présent</td>\n",
       "      <td>179428</td>\n",
       "      <td>Bachelor semestre 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Civilité          Nom Prénom   Statut  No Sciper             Semester\n",
       "0  Monsieur   Arévalo Christian  Présent     169569  Bachelor semestre 1\n",
       "1  Monsieur     Aubelle Flavien  Présent     174905  Bachelor semestre 1\n",
       "2  Monsieur       Badoud Morgan  Présent     173922  Bachelor semestre 1\n",
       "3  Monsieur  Baeriswyl Jonathan  Présent     179406  Bachelor semestre 1\n",
       "4  Monsieur     Barroco Michael  Présent     179428  Bachelor semestre 1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suppose in the next cell that a semester is 6 months. This is fair, we don't really want to know the number of months spent **on campus**, we are intersted in knowing the number of months spent **as registered at EPFL**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create one single big dataframe \n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# Drop the status\n",
    "df = df.drop(['Statut'], axis=1)\n",
    "\n",
    "# Drop people what does not contain Bachelor 1 and Bachelor 6\n",
    "df = df.groupby('No Sciper').filter(lambda group: 'Bachelor semestre 1' in group['Semester'].unique()\n",
    "                              and 'Bachelor semestre 6' in group['Semester'].unique())\n",
    "\n",
    "# Count in each group, the number of entries in the semester column\n",
    "df = df.groupby(['No Sciper', 'Nom Prénom', 'Civilité']).agg('count')\n",
    "\n",
    "# Reset the index and group by sex\n",
    "grouped = df.reset_index().groupby('Civilité')\n",
    "\n",
    "# Get the values, these are the number of semester\n",
    "female_values = grouped.get_group('Madame')['Semester']\n",
    "male_values = grouped.get_group('Monsieur')['Semester']\n",
    "\n",
    "# Suppose a semester is 6 months\n",
    "female_values *= 6\n",
    "male_values *= 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a Two-Sample T-test on our values. We can apply this test because it tests if, given two sample means, we can say that the samples are significantly different or not.\n",
    "Our Null Hypothesis $H_0$ here is that the two means are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.0643000334248713, pvalue=0.28784297465161934)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the stats library\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Perfom the T-test\n",
    "stats.ttest_ind(female_values.values, male_values.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, the probability of getting our samples, given $H_0$ is true is $0.287$. Which is high, so we fail to reject the Null Hypothesis, and we say that **is not statistically significant**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will perfom a similar analysis on the master students. \n",
    "First we need to fetch all the data again, we are interested in the following tables : Master semestre 1, Master semestre 2, Master semestre 3 and Projet Master.\n",
    "We decided to not take the two last years into account, the reason is we don't know yet if these students are going to stay at EPFL or not. For example, a Master 1 student this current year would be counted as staying only one semester at EPFL, which is wrong, he would probably finish his master here, so we can't count him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Informatique_2014-2015_Semestre de printemps_Projet Master printemps empty, skipping it...\n"
     ]
    }
   ],
   "source": [
    "# We need to redefine the pedagocial periods \n",
    "peda_period = [['Master semestre 1', 'Master semestre 3', 'Projet Master automne'], \n",
    "               ['Master semestre 2', 'Projet Master printemps']]\n",
    "\n",
    "# We also decided to not take the two last years into account.\n",
    "acad_period = acad_period[:-2]\n",
    "\n",
    "# Define a list of dataframes\n",
    "dfs = []\n",
    "\n",
    "# Get all the possible files\n",
    "for year in acad_period: \n",
    "    for season in semester_type:\n",
    "        # Take only odd or even semesters, depending on the season\n",
    "        semesters = peda_period[0] if season == semester_type[0] else peda_period[1]\n",
    "        for sem in semesters: \n",
    "            filters = [section, year, season, sem]\n",
    "            filename = 'data/' + '_'.join(filters)\n",
    "            \n",
    "            # Get the request parameters\n",
    "            params = get_parameters(format, [section, year, season, sem])\n",
    "            \n",
    "            # Save the data\n",
    "            get_data(params, format, filename)\n",
    "            \n",
    "            # Read the file\n",
    "            try:\n",
    "                df = pd.read_html(filename + '.' + format, skiprows=[0], header=0)[0]\n",
    "            except IndexError:\n",
    "                print('File %s empty, skipping it...' % filename)\n",
    "            \n",
    "            # Drop the NaN values, add the semester column\n",
    "            df['Semester'] = sem\n",
    "            df = df.dropna(axis=1, how='all')\n",
    "            \n",
    "            # Add to the list\n",
    "            dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start to process the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average stay at EPFL for a master student is 3.096022 semesters.\n"
     ]
    }
   ],
   "source": [
    "# Create one big data frame\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# Let's drop the exchange related columns, that we dont use in this context\n",
    "df = df.drop(['Ecole Echange', 'Type Echange', 'Statut'], axis=1)\n",
    "\n",
    "# Group by students, this gives us the number of Mineur, Semesters and Specialisations for each student\n",
    "df = df.groupby(['No Sciper', 'Nom Prénom', 'Civilité']).agg('count')\n",
    "\n",
    "# Compute the average stay at EPFL\n",
    "average_stay = df['Semester'].mean()\n",
    "print('The average stay at EPFL for a master student is %f semesters.' % average_stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
